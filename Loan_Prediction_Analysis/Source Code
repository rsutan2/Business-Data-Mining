---
title: "Loan Prediction Analysis - Lending Club"
output: html_document
date: '2022-10-31'
---

setwd("~/Documents/IDS 572/Assignment 2")
```{r}
library(tidyverse)
library(lubridate)
```

```{r}
lcdf <- read_csv('lcDataSampleFall22.csv')
```

```{r}
#1b Take a look at the data attributes. How would you categorize these attributes, 
# in broad terms, considering what they pertain to?
head(lcdf) %>% str()
```

#2a (i) What is the proportion of defaults (‘charged off’ vs ‘fully paid’ loans) in the data?
# How does default rate vary with loan grade? Does it vary with sub-grade? And is this what you would expect, and why?
```{r}
# Count loans that are fully-paid and charged-off
lcdf %>% group_by(loan_status) %>% tally()

# Group loan status by loan grade
lcdf %>% group_by(grade, loan_status) %>% tally()

# Find the percentage of fully-paid and charged-off within grade and sub grade:
prop.table(table(lcdf$loan_status, lcdf$grade),margin = 2) 
prop.table(table(lcdf$loan_status, lcdf$sub_grade),margin = 2) 

# View default rate by grade in graph & bar chart mode
graph <- lcdf %>% group_by(grade) %>% summarise(Count = n(), DefaultRate = (sum(loan_status == "Charged Off")/Count)*100)
ggplot(graph) + aes(x = grade, y = DefaultRate, fill = grade) + geom_bar(stat = "identity") + xlab("Grade") + ylab("Default Rate")

# View default rate by sub grade in graph & bar chart mode
graph1 <- lcdf %>% group_by(sub_grade) %>% summarise(Count = n(), DefaultRate = (sum(loan_status == "Charged Off")/Count)*100)
ggplot(graph1) + aes(x = sub_grade, y = DefaultRate, fill = sub_grade) + geom_bar(stat = "identity") + xlab("Sub Grade") + ylab("Default Rate")
```
#2a (ii) How many loans are there in each grade? And do loan amounts vary by grade? 
# Does interest rate for loans vary with grade, subgrade? 
# Look at the average, standard-deviation, min and max of interest rate by grade and subgrade. 
# Is this what you expect, and why?
```{r}
# Classification by grade
summarise_by_grade <- lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate),minInterest=min(int_rate), maxInterest=max(int_rate), avgLoanAMt=mean(loan_amnt))

# Classification by subgrade
lcdf %>% group_by(sub_grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate),minInterest=min(int_rate), maxInterest=max(int_rate), avgLoanAMt=mean(loan_amnt))

# Loan Amount Variation by grade
ggplot(lcdf) + aes(x = grade, y = loan_amnt, fill = grade) + geom_boxplot() + xlab("Grade") + ylab("Loan Amount") + ggtitle("Loan Amount Variation by Grade")

# Loan Interest Rate Variation by grade
ggplot(lcdf) + aes(x = grade, y = int_rate, fill = grade) + geom_boxplot() + xlab("Grade") + ylab("Interest Rate") + ggtitle("Interest Rate Variation by Grade")

# Loan Interest Rate Variation by subgrade
ggplot(lcdf) + aes(x = sub_grade, y = int_rate, colour= sub_grade) + geom_point() + xlab("Sub Grade") + ylab("Interest Rate") + ggtitle("Interest Rate Variation by Sub Grade") + theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

#2a (iii) For loans which are fully paid back, how does the time-to-full-payoff vary? 
# For this, calculate the ‘actual term’ (issue-date to last-payment-date) for all loans. How does this actual-term vary by loan grade (a box-plot can help visualize this). 
```{r}
# Check format of last payment date and issued date
head(lcdf[, c("last_pymnt_d", "issue_d")])

# Change character type to date variable
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d, "myd")

# Set the actual-term to 3 years for actual default loans
lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d %--% lcdf$last_pymnt_d)/dyears(1), 3)
lcdf_paid <- subset(lcdf, loan_status == "Fully Paid")
str(lcdf_paid)

# Boxplot actual term by grade
library(ggplot2)
ggplot(lcdf_paid, aes(x=grade, y=actualTerm, fill=grade)) +
  geom_boxplot() + xlab("Grade") + ylab("Actual Term (years)") + ggtitle("Actual Term by Grade")

# Check Actual Term by Grade
lcdf_paid %>% group_by(grade) %>% summarise(avgActTerm= mean(actualTerm), minActTerm=min(actualTerm), maxActTerm=max(actualTerm))
```


#2a (iv) Calculate the annual return. Show how you calculate the percentage annual return.
# Is there any return from loans which are ‘charged off’? Explain. How does return from charged-off loans vary by loan grade?
# Compare the average return values with the average interest-rate on loans – do you notice any differences, and how do you explain this?
# How do returns vary by grade, and by sub-grade.
# If you wanted to invest in loans based on this data exploration, which loans would you invest in?
```{r}
# Find actual annual return based on actual term
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm), 0)
summary(lcdf$actualReturn)

# Find return from loans which are ‘charged off’ and find whether return from charged-off loans vary by loan grade
lcdf_charged_off <- subset(lcdf, loan_status == "Charged Off")

# Find return for charged off loans
lcdf_charged_off %>% summarise(retValue=total_pymnt-funded_amnt) %>% filter(retValue > 0)
lcdf_charged_off %>% filter(total_pymnt > 0) %>% group_by(grade) %>% summarise(totPayment=mean(total_pymnt))
lcdf_charged_off %>% group_by(grade) %>% summarise(nLoans=n(), actRet= (mean(actualReturn)))

# How returns vary by grade and sub-grade
lcdf %>% group_by(grade) %>% summarise(avgReturn= mean(actualReturn), avgInt= mean(int_rate)/100)
lcdf %>% group_by(sub_grade) %>% summarise(avgReturn= mean(actualReturn), avgInt= mean(int_rate)/100)

# Calculate total return
lcdf$totReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt), 0) #not annual return

(lcdf_chargedoff_return<-lcdf_charged_off %>% group_by(grade) %>% summarise(nLoans=n(), actRet= (mean(actualReturn)), intRate=mean(int_rate)))

lcdf %>% group_by(sub_grade) %>% summarise(nLoans=n(), annRet=mean(actualReturn), TotRet=mean(totReturn), defaults=sum(loan_status=="Charged Off"), defRate=(sum(loan_status=="Charged Off")/n()), return_to_risk_ratio=(mean(actualReturn)/(sum(loan_status=="Charged Off")/n())))

# Graphing the codes
# Actual Return from Charged Off Loans by Grade
ggplot(lcdf_chargedoff_return) + aes(x = grade, y = actRet, fill = grade) + geom_bar(stat ="identity") + xlab("Grade") + ylab("Return from Charged Off") + ggtitle("Actual Return from Charged Off Loans by Grade") +theme(axis.text.x = element_text(angle = 60, hjust = 1))

# Actual Return of All Loans by Grade
lcdf_all_return_grade<-lcdf %>% group_by(grade) %>% summarise(nLoans=n(), actRet= (mean(actualReturn)), intRate=mean(int_rate))
ggplot(lcdf_all_return_grade) + aes(x = grade, y = actRet, fill = grade) + geom_bar(stat ="identity") + xlab("Grade") + ylab("Return from All") + ggtitle("Actual Return from All Loans by Grade") +theme(axis.text.x = element_text(angle = 60, hjust = 1))

# Actual Return of All Loans by Sub Grade
lcdf_all_return_subgrade<-lcdf %>% group_by(sub_grade) %>% summarise(nLoans=n(), actRet= (mean(actualReturn)), intRate=mean(int_rate))
ggplot(lcdf_all_return_subgrade) + aes(x = sub_grade, y = actRet, fill = sub_grade) + geom_bar(stat ="identity") + xlab("Sub Grade") + ylab("Return from All") + ggtitle("Actual Return from All Loans by Sub Grade") +theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

#2a (v) What are people borrowing money for (purpose)? Examine how many loans, average amounts, etc. by purpose? 
# Do loan amounts vary by purpose? Do defaults vary by purpose?
# Does loan-grade assigned by Lending Club vary by purpose?
```{r}
lcdf %>% group_by(purpose) %>% summarise(nLoans=n(), avgLoanAMt=mean(loan_amnt))
lcdf_purpose_1 <- lcdf %>% group_by(grade) %>% summarise(nLoans=n(), avgLoanAMt=mean(loan_amnt))
lcdf %>% group_by(grade, purpose) %>% summarise(nLoans=n(), avgLoanAMt=mean(loan_amnt))

# Find the distribution of grades within purposes:
table(lcdf$purpose, lcdf$loan_status)
prop.table(table(lcdf$purpose, lcdf$loan_status), 1) # % by purpose

# Bar chart for the loan count by purpose
ggplot(lcdf, aes(x = purpose, fill = purpose)) + geom_bar(width = 0.5) + xlab("Purpose") + ylab("Loan Count") + theme(axis.text.x = element_text(angle = 60, hjust = 1)) + ggtitle("Loan Count by Purpose")

# Boxplot for the loan amount by purpose (for average)
ggplot(lcdf) + aes(x = purpose, y = loan_amnt, fill = purpose) + geom_boxplot() + xlab("purpose") + ylab("Loan Amount") + ggtitle("Loan Amount by Purpose") + theme(axis.text.x = element_text(angle = 60, hjust = 1))

# Bar chart of default risk by purpose
lcdf_by_purpose <- lcdf %>% group_by(purpose) %>% summarise(Count = n(), DefaultRate = (sum(loan_status == "Charged Off")/Count)*100)
ggplot(lcdf_by_purpose) + aes(x = purpose, y = DefaultRate, fill = purpose) + geom_bar(stat = "identity") + xlab("Purpose") + ylab("Default Rate") + ggtitle("Default Rate by Purpose") +theme(axis.text.x = element_text(angle = 60, hjust = 1))

#Bar chart for loan grade by purpose
ggplot(lcdf) +geom_bar(aes(x = as.factor(grade) , fill = purpose),position = "dodge", stat = "count") + ggtitle("Loan Grade by Purpose")
```

#2a (vi) Consider some borrower characteristics like employment-length, annual-income, fico-scores (low, high). 
# How do these relate to loan attributes like, for example, loan_amout, loan_status, grade, purpose, actual return, etc.
```{r}
# Employment-length and loan purpose
ggplot(lcdf) +
  geom_bar(aes(x = as.factor(purpose) , fill = emp_length),
           position = "dodge", stat = "count")

# Employment-length and grade
ggplot(lcdf) +
  geom_bar(aes(x = as.factor(grade) , fill = emp_length),
           position = "dodge", stat = "count")

# Total payment and loan status
ggplot(lcdf) +
     geom_bar(aes(x = as.factor(loan_status) , fill = total_pymnt),
              position = "dodge", stat = "count")
```

#2a (vii) Generate some (at least 3) new derived attributes which you think may be useful for predicting default., 
# and explain what these are. For these, do an analyses as in the questions above (as reasonable based on the derived variables).
```{r}
# Proportion of satisfactory bankcard accounts
lcdf$propSatisBankcardAccts <- ifelse(lcdf$num_bc_tl>0, lcdf$num_bc_sats/lcdf$num_bc_tl, 0)

# the length of borrower's history with LC
lcdf$earliest_cr_line<-paste(lcdf$earliest_cr_line, "-01", sep = "")
lcdf$earliest_cr_line<-parse_date_time(lcdf$earliest_cr_line, "myd")
lcdf$borrHistory <- as.duration(lcdf$earliest_cr_line %--% lcdf$issue_d) / dyears(1)

# ratio of loan amount to annual income
lcdf$propLoanAmt_to_AnnInc <- lcdf$loan_amnt/lcdf$annual_inc
```

#2b Are there missing values? What is the proportion of missing values in different variables?
#Explain how you will handle missing values for different variables. You should consider what he
#variable is about, and what missing values may arise from – for example, a variable
#monthsSinceLastDeliquency may have no value for someone who has not yet had a delinquency;
#what is a sensible value to replace the missing values in this case?
#Are there some variables you will exclude from your model due to missing values?
```{r}
#Check NA before removal:
colMeans(is.na(lcdf))
dim(lcdf) #151 variables
#drop variables with all NAs:
lcdf <- lcdf %>% select_if(function(x){!all(is.na(x))})
dim(lcdf)
#Dropped columns until 114 variables
#Of the columns remaining, names of columns with missing values
names(lcdf)[colSums(is.na(lcdf))>0]
#missing value proportions in each column
colMeans(is.na(lcdf))
# or, get only those columns where there are missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]
#remove variables which have more than 60% missing values, because the data available is insufficient to predict missing values.
nm<-names(lcdf)[colMeans(is.na(lcdf))>0.6]
lcdf <- lcdf %>% select(-nm)
#Impute missing values - first get the columns with missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]
#summary of data in these columns
nm<- names(lcdf)[colSums(is.na(lcdf))>0]
summary(lcdf[, nm])
#mths_since_last_delinq: has 48% missings, these pertain to no delinquincy, so replace by a value higher than the max (500) -- we will try this out and put results in a temporary dataset lcx, with the attributes that have missn g values
lcx<-lcdf[, c(nm)]
colMeans(is.na(lcx))[colMeans(is.na(lcx))>0]

lcx<- lcx %>% replace_na(list(mths_since_last_delinq = 500)) #bc_open_to_buy, use mean because number of NA is really low (1.2%)
lcx<- lcx %>% replace_na(list(bc_open_to_buy=mean(lcdf$bc_open_to_buy, na.rm=TRUE)))
#Replace na in last_credit_pull_d with a date older than 1 year(valid period). In this case we chose 1 Jan 2015.
lcx<- lcx %>% replace_na(list(last_credit_pull_d='01-01-2015'))

sum(is.na(lcx$last_credit_pull_d)>0) #prove we replaced the NAs

#mo_sin_old_il_acct, use mean because number of NA is really low (3.8%)
lcx<- lcx %>% replace_na(list(mo_sin_old_il_acct=max(lcdf$mo_sin_old_il_acct, na.rm=TRUE)))
#mths_since_recent_bc, use max because NA because it means the person has never opened a bankcard acc before. So
#we assign a number that is the longest, or way above the max.
lcx<- lcx %>% replace_na(list(mths_since_recent_bc=max(lcdf$mths_since_recent_bc, na.rm=TRUE)))
#mths_since_recent_inq, use max because NA because it means no inquiry has been made. So we assign a number that
#is the longest, or way above the max.
lcx<- lcx %>% replace_na(list(mths_since_recent_inq=max(lcdf$mths_since_recent_inq, na.rm=TRUE)))
#bc_util, use mean because number of NA is really low (1.2%)
lcx<- lcx %>% replace_na(list(bc_util=mean(lcdf$bc_util, na.rm=TRUE)))

#listnum_tl_120dpd_2m, use mean because number of NA is really low (2.6%)
lcx<- lcx %>% replace_na(list(num_tl_120dpd_2m = mean(lcdf$num_tl_120dpd_2m, na.rm=TRUE))) #percent_bc_gt_75, use mean because number of NA is really low (1.2%)
lcx<- lcx %>% replace_na(list(percent_bc_gt_75 = mean(lcdf$percent_bc_gt_75, na.rm=TRUE))) #revol_util, use mean because number of NA is really low (.04%)
lcx<- lcx %>% replace_na(list(revol_util = mean(lcdf$revol_util, na.rm = TRUE))) #emp_length, NA means 0 experience, so replace it with < 1 year
lcx<- lcx %>% replace_na(list(emp_length= "< 1 year"))
#After trying this out on the temporary dataframe lcx, if we are sure this is what we want, we can now replace t he missing values on the lcdf dataset
lcdf<- lcdf %>% replace_na(list(mths_since_last_delinq=500,bc_open_to_buy=mean(lcdf$bc_open_to_buy, na.rm=TRUE),last_credit_pull_d='01-01-2015', mo_sin_old_il_acct=max(lcdf$mo_sin_old_il_acct, na.rm=TRUE), mths_since_recent_bc=max(lcdf$mths_since_recent_bc, na.rm=TRUE), mths_since_recent_inq=max(lcdf$mths_since_recent_inq, na.rm=TRUE),bc_util=mean(lcdf$bc_util, na.rm=TRUE), num_tl_120dpd_2m = mean(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = mean(lcdf$percent_bc_gt_75, na.rm=TRUE), revol_util = mean(lcdf$revol_util, na.rm = TRUE), emp_length= "< 1 year"))

#CHECK FOR NAs AGAIN
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]

# The last payment date missing are from 'Charger Off' where they didn't pay at all.
lcdf %>% filter(is.na(lcdf$last_pymnt_d)) %>% group_by(loan_status) %>% tally()

##########leakage value
#Drop some other columns which are not useful and those which will cause 'leakage'
lcdf <- lcdf %>% select(-c(funded_amnt_inv, term, emp_title, pymnt_plan, title, zip_code, addr_state, out_prncp,
out_prncp_inv, total_pymnt_inv, total_rec_prncp, total_rec_int, last_credit_pull_d, policy_code, disbursement_method, debt_settlement_flag, hardship_flag, application_type))

#Drop some other variables
varsToRemove <- c("inq_last_6mths",
                  "acc_open_past_24mths",
                  "bc_open_to_buy",
                  "collection_recovery_fee",
                  "collections_12_mths_ex_med",
                  "earliest_cr_line",
                  "funded_amnt",
                  "initial_list_status",
                  "issue_d",
                  "last_pymnt_amnt",
                  "last_pymnt_d",
                  "mo_sin_old_il_acct",
                  "mo_sin_old_rev_tl_op",
                  "mo_sin_rcnt_rev_tl_op",
                  "mo_sin_rcnt_tl",
                  "mths_since_recent_bc",
                  "mths_since_recent_inq",
                  "num_actv_bc_tl",
                  "num_actv_rev_tl",
                  "num_bc_sats",
                  "num_bc_tl",
                  "num_il_tl",
                  "num_tl_30dpd",
                  "num_tl_90g_dpd_24m",
                  "open_acc",
                  "pct_tl_nvr_dlq",
                  "percent_bc_gt_75",
                  "recoveries",
                  "tax_liens",
                  "tot_coll_amt",
                  "total_il_high_credit_limit",
                  "total_rec_late_fee",
                  "total_rev_hi_lim"
)
```

```{r}
lcdf <- lcdf %>% select(-varsToRemove)
```

#3 Do a univariate analyses to determine which variables (from amongst those you decide to
#consider for the next stage prediction task) will be individually useful for predicting the
#dependent variable (loan_status). For this, you need a measure of relationship between the
#dependent variable and each of the potential predictor variables. Given loan-status as a binary
#dependent variable, which measure will you use? 
#From your analyses using this measure, which variables do you think will be useful for predicting loan_status?
#(Note – if certain variables on their own are highly predictive of the outcome, it is good to ask if
#this variable has a leakage issue).
#We will next develop predictive models for loan_status. 
```{r}
lcdf %>% group_by(emp_length) %>% tally()
lcdf$emp_length <- factor(lcdf$emp_length, levels=c("n/a", "< 1 year","1 year","2 years", "3 years" ,  "4 years",   "5 years",   "6 years",   "7 years" ,  "8 years", "9 years", "10+ years" ))
table(lcdf$loan_status, lcdf$emp_length)
cc=table(lcdf$loan_status, lcdf$emp_length)
cc[1,]/(cc[1,] + cc[2,])
table(lcdf$grade, lcdf$emp_length)

library(pROC) #this package has a function auc(..) which we can readily use

# For example:
auc(response=lcdf$loan_status, lcdf$loan_amnt)
 # returns the auc value for loan_amt as the single predictor

#In the auc(..) function, the predictor variable has to be numeric  - otherwise, how would it calculate the AUC (think about how auc is calculated). 
# For a factor variable, we can consider the factor levels as numbers:
auc(response=lcdf$loan_status, as.numeric(lcdf$emp_length))

# For the numeric variables:
aucsNum<-sapply(lcdf %>% select_if(is.numeric), auc, response=lcdf$loan_status)
  #Please make sure we understand what is happening here.  How does sapply work?

#Or considering both numeric and factor variables:
aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response=lcdf$loan_status) 
#aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), pROC::auc, response=lcdf$loan_status)

library(broom)
tidy(aucAll[aucAll > 0.5]) %>% view()
```

```{r}
#TO determine which variables have auc > 0.5
aucAll[aucAll>0.5]

#Or, we can use the tidy(..) function from the broom package - which converts the 'messy' output into a tidy form as a tibble
library(broom)
tidy(aucAll[aucAll > 0.5]) %>% view()

# or  in any range of values like, tidy(aucAll[aucAll >=0.5 & aucAll < 0.6])
# or in sorted order
tidy(aucAll) %>% arrange(desc(aucAll))
```

#4ab Split the data into training and validation sets. What proportions do you consider, why?
#4b For evaluation of models, you should include confusion matrix related measures, as well as ROC analyses and lifts. Explain which performance measures you focus on, and why.

#5 Develop a decision tree model to predict default.
#Train decision tree models (use either rpart or c50)
#What parameters do you experiment with, and what performance do you obtain (on training
#and validation sets)? Clearly tabulate your results and briefly describe your findings.
#[If something looks too good, it may be due to leakage – make sure you address this]

```{r}
nr=nrow(lcdf)
trnIndex = sample(1:nr, size = round(0.7*nr), replace=FALSE)
lcdfTrn=lcdf[trnIndex,]
lcdfTst = lcdf[-trnIndex,]

dim(lcdfTrn)
dim(lcdfTst)
```

```{r}

# Build Decision Tree using rpart
library(rpart)
library(ROCR)
library(pROC)

#Set prior to 0.5 - 0.5: decreasing xerror pattern as expected in the CP table, but low accuracy.
rpDT1 <- rpart(loan_status ~., data=subset(lcdfTrn, select=-c(annRet=mean(actualReturn), actualTerm, actualReturn,total_pymnt)), method="class", parms = list(split = "information", prior=c(0.5,0.5)), control = rpart.control(minsplit = 30, cp=0.00))

rpDT1<-prune(rpDT1,cp=0.00022)
printcp(rpDT1)

#confusion matrix on training data
table(pred=predict(rpDT1,lcdfTrn, type="class"), true=lcdfTrn$loan_status)

predTrn1=predict(rpDT1,lcdfTrn, type="class")
mean(predTrn1 == lcdfTrn$loan_status)

#confusion matrix on test data
table(pred=predict(rpDT1,lcdfTst, type="class"), true=lcdfTst$loan_status)

predTst1=predict(rpDT1, lcdfTst, type='class')
mean(predTst1 == lcdfTst$loan_status)

rpDT1$variable.importance
#write.csv(rpDT1$variable.importance,"output_rpart_var_importance.csv")

#Set prior according to the class proportions. Increasing xerror, but higher accuracy.
#total_pymnt

rpDT2 <- rpart(loan_status ~., data=subset(lcdfTrn, select=-c(annRet=mean(actualReturn), actualTerm, actualReturn,total_pymnt)), method="class", parms = list(split = "information", prior=c(1-0.171,0.171)), control = rpart.control(minsplit = 30, cp=0.00))

#prior=c(0.5,0.5)),
rpDT2<-prune(rpDT2,cp=0.0002)
printcp(rpDT2)

#confusion matrix on training data
table(pred=predict(rpDT2,lcdfTrn, type="class"), true=lcdfTrn$loan_status)

predTrn2=predict(rpDT2,lcdfTrn, type="class")
mean(predTrn2 == lcdfTrn$loan_status)

#confusion matrix on test data
table(pred=predict(rpDT2,lcdfTst, type="class"), true=lcdfTst$loan_status)

predTst2=predict(rpDT2, lcdfTst, type='class')
mean(predTst2 == lcdfTst$loan_status)

rpDT2$variable.importance
#write.csv(rpDT2$variable.importance,"output_rpart_var_importance.csv")

#AUC ROC rpDT2
#ROC On Train Data
predTrnProb_rpDT2=predict(rpDT2, lcdfTrn, type='prob')
predTrnProb_rpDT2_FP <- predTrnProb_rpDT2[, 'Fully Paid']

auc_rpDT2_Trn <- auc(lcdfTrn$loan_status, predTrnProb_rpDT2_FP)
auc_rpDT2_Trn
rpDT2_roc_Trn = roc(lcdfTrn$loan_status, predTrnProb_rpDT2_FP)
plot(rpDT2_roc_Trn, main = "Rpart ROC Curve on Train Data")

#ROC On Test Data
predTstProb_rpDT2=predict(rpDT2, lcdfTst, type='prob')
predTstProb_rpDT2_FP <- predTstProb_rpDT2[, 'Fully Paid']

auc_rpDT2_Tst <- auc(lcdfTst$loan_status, predTstProb_rpDT2_FP)
auc_rpDT2_Tst

rpDT2_roc_Tst = roc(lcdfTst$loan_status, predTstProb_rpDT2_FP)

#Lift Curve on Train Data
plot(rpDT2_roc_Tst, main="Rpart ROC Curve on Test Data")
scoreTrn_rpart <- predict(rpDT2, lcdfTrn, type="prob")[,'Charged Off']
rocPredTrn_rpart <- prediction(scoreTrn_rpart, lcdfTrn$loan_status, label.ordering = c('Fully Paid', 'Charged Off'))
liftPerf_rpart_Trn <-performance(rocPredTrn_rpart, "lift", "rpp")
plot(liftPerf_rpart_Trn, main = "Rpart Lift Curve on Train Data")

#Lift Curve on Test Data
scoreTst_rpart <- predict(rpDT2, lcdfTst, type="prob")[,'Charged Off']
rocPredTst_rpart <- prediction(scoreTst_rpart, lcdfTst$loan_status, label.ordering = c('Fully Paid', 'Charged Off'))
liftPerf_rpart_Tst <-performance(rocPredTst_rpart, "lift", "rpp")
plot(liftPerf_rpart_Tst, main = "Rpart Lift Curve on Test Data")
```
#Q6 (a) Develop random forest and boosted tree model (using gbm or xgb)
# Note the ‘ranger’ library and xgb can give faster computations. 
# What parameters do you experiment with, and how does this affect performance?
# Describe the best random forest and boosted tree model in terms of number of trees, performance, variable importance.
# (b)Compare the performance of random forest, boosted tree and decision tree model from Q 5 above. Do you find the importance of variables to be different ?
# Which model would you prefer, and why ?
```{r}
library(tidyverse)
library(lubridate)

lcdf <- read_csv('lcDataSampleFall22.csv')
lcdf <- lcdf %>% filter(loan_status == "Fully Paid" | loan_status == "Charged Off")

#Term of the loan is the duration between the last-payment-date and the loan issue-date.
# check the format of these two columns with date values
head(lcdf[, c("last_pymnt_d", "issue_d")])
# change the character type to date:
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
# convert this character to a date type variable
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")
# for defaulted loans, set the actual-term at 3 years.
lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1), 3)
#Based on actual term, the actual annual return is
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm), 0)
lcdf$annRet <- ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#NA Removal
#drop variables with all NAs:
lcdf <- lcdf %>% select_if(function(x){!all(is.na(x))})
#remove variables which have more than 60% missing values, because the data available is insufficient to predict missing values.
nm<-names(lcdf)[colMeans(is.na(lcdf))>0.6]
lcdf <- lcdf %>% select(-nm)
lcdf<- lcdf %>% replace_na(list(mths_since_last_delinq=500, bc_open_to_buy=mean(lcdf$bc_open_to_buy, na.rm=TRUE),  last_credit_pull_d='01-01-2015', mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, bc_util=median(lcdf$bc_util, na.rm=TRUE), num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm=TRUE), revol_util = median(lcdf$revol_util, na.rm = TRUE), emp_length= "< 1 year"))
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]
```


```{r}
#DATA LEAKAGE
#Drop some other variables
varsToRemove <- c("avg_cur_bal",
                  "funded_amnt",
                  "funded_amnt_inv",
                  "term",
                  "emp_title",
                  "issue_d",
                  "delinq_2yrs",
                  "pymnt_plan",
                  "title",
                  "zip_code",
                  "addr_state",
                  "delinq_2yrs",
                  "inq_last_6mths", 
                  "mths_since_last_delinq",
                  "open_acc",
                  "pub_rec",
                  "revol_bal",
                  "revol_util",
                  "total_acc",
                  "out_prncp",
                  "out_prncp_inv",
                  "total_pymnt_inv",
                  "total_rec_prncp",
                  "total_rec_int",
                  "total_rec_late_fee",
                  "recoveries",
                  "collection_recovery_fee",
                  "last_pymnt_d",
                  "last_pymnt_amnt",
                  "last_credit_pull_d",
                  "policy_code",
                  "application_type",
                  "acc_now_delinq",
                  "tot_coll_amt",
                  "tot_cur_bal",
                  "hardship_flag",
                  "disbursement_method",
                  "debt_settlement_flag",
                  "earliest_cr_line",
                  "num_tl_op_past_12m",
                  "percent_bc_gt_75",
                  "verification_status",
                  "num_rev_tl_bal_gt_0",
                  "num_actv_rev_tl",
                  "num_actv_bc_tl",
                  "pub_rec_bankruptcies",
                  "num_accts_ever_120_pd",
                  "collections_12_mths_ex_med",
                  "num_tl_90g_dpd_24m",
                  "num_tl_120dpd_2m"
)
lcdf <- lcdf %>% select(-varsToRemove)
```

```{r}
#change chr to factors:
lcdf$grade <- factor(lcdf$grade, levels=c("A", "B","C","D", "E","F","G"))
lcdf$sub_grade <- factor(lcdf$sub_grade, levels=c("A1", "A2", "A3", "A4", "A5", "B1", "B2", "B3", "B4", "B5", "C1", "C2", "C3", "C4", "C5", "D1", "D2", "D3", "D4", "D5", "E1", "E2", "E3", "E4", "E5", "F1", "F2", "F3", "F4", "F5", "G1", "G2", "G3", "G4", "G5"))
#lcdf$verification_status <- as.factor(lcdf$verification_status)
lcdf$initial_list_status <- factor(lcdf$initial_list_status, levels=c("w", "f"))
lcdf$loan_status <- factor(lcdf$loan_status, levels=c("Fully Paid", "Charged Off"))
lcdf$emp_length <- factor(lcdf$emp_length, levels=c("n/a", "< 1 year","1 year","2 years", "3 years" ,  "4 years",   "5 years",   "6 years",   "7 years" ,  "8 years", "9 years", "10+ years" ))
lcdf$purpose <- fct_recode(lcdf$purpose, other="wedding", other="educational", other="renewable_energy")
lcdf$home_ownership <- as.factor((lcdf$home_ownership))
```
```{r}
library(dplyr)
library(ggraph)
library(igraph)
library(randomForest)
library(caret)
#library("xlsx")
library(ranger)
rgModel1 <- ranger(loan_status ~., data=subset(lcdfTrn, select=-c(annRet=mean(actualReturn), actualTerm, actualReturn, total_pymnt)), num.trees =200, importance='permutation', mtry = 7, max.depth = 10, min.node.size = 30, sample.fraction = 0.5, replace=FALSE, respect.unordered.factors = "order" , verbose = TRUE , seed=0)
#Summary()
vimpRg_1 <- ranger::importance(rgModel1)
write.csv(vimpRg_1,"output_Ranger_var_importance.csv")
#write.xlsx(vimpRg_1, file, sheetName = "Sheet1", 
#  col.names = TRUE, row.names = TRUE, append = FALSE)
#scoreTst <- predict(rgModel1,lcdfTst)
#head(scoreTst)$predictions
#scoreTst <- scoreTst$predictions[,"Fully Paid"]
#Predict model using training data
predTrn<- predict(rgModel1,up_lcdfTrn)
predTst<- predict(rgModel1,up_lcdfTst)
#create confusion matrix for Training data
Conf_Trn<-table(predictions(predTrn), up_lcdfTrn$loan_status)
confusionMatrix(Conf_Trn,positive = "Charged Off")
#create confusion matrix for Test data
Conf_Tst<-table(predictions(predTst), up_lcdfTst$loan_status)
confusionMatrix(Conf_Tst,positive = "Charged Off")
rgModelProb <- ranger(loan_status ~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, actualReturn, total_pymnt)),
num.trees =200, importance='permutation', mtry = 7, max.depth = 10, min.node.size = 30, sample.fraction = 0.5, replace=FALSE, respect.unordered.factors = "order" , verbose = TRUE , seed=0, probability = TRUE)
scoreTrn <- predict(rgModelProb,lcdfTrn)
head(scoreTrn)$predictions
scoreTrn_FP <- scoreTrn$predictions[,"Fully Paid"]
vimpRg_1 <- ranger::importance(rgModelProb)
vimpRg_1 
#evaluate AUC and ROC
library(pROC)
auc_rg_Trn <- auc(lcdfTrn$loan_status, scoreTrn_FP)
rg_roc_Trn <- roc(lcdfTrn$loan_status, scoreTrn_FP)
plot(rg_roc_Trn)
#Test data ROC AUC
scoreTst <- predict(rgModelProb,lcdfTst)
head(scoreTst)$predictions
scoreTst_FP <- scoreTst$predictions[,"Fully Paid"]
#evaluate AUC and ROC
auc_rg_Tst <- auc(lcdfTst$loan_status, scoreTst_FP)
rg_roc_Tst <- roc(lcdfTst$loan_status, scoreTst_FP)
plot(rg_roc_Tst)
```


```{r}
#now apply the prediction function from ROCR to get a prediction object
library(ROCR)
rocPredTst <- prediction(scoreTst_FP, lcdfTst$loan_status, label.ordering = c('Charged Off','Fully Paid'))
liftPerf <-performance(rocPredTst, "lift", "rpp")
plot(liftPerf)
```

```{r}
#Q7 Analysis:
#This part of the assignment seems like a natural extension to question 2(V). Some aspect of the questions have been answered in 2(V). For the sake of completion we have decided to repeat our previous analysis for the purpose of providing reader a exhaustive report. We have previously calculated/received several factors such as interest rate, average interest rate, average return rate.

#Interest rate cannot be direct indicator of profit because we also have to consider the amount we investor has put in to earn the money. Using the well known formula for profit:
#Profit= Revenue - Cost

#total payment based on Interest rate basically present the overall revenue from which we need to get rid of Cost price which in this case in funded amount. We get actual return using the mentioned method which we divide by duration to achieve the annual return aka actual interest rate to achieve the annual return.


#In the table below we have presented an average estimate about how the return looks like in 3 year. we have considered the fact that average duration for paid off loans is not 3 years but averages around 2.1 year. We have added 2 % certificate of deposit rate which is the risk free rate. 3 year rate is averaging around 8% and even reaches up to 10% for most profitable business.

#Further to that we have chosen our best models that we created using rpart,ranger and c50 strategy and tried to come up with investment strategy about investing 100usd. we allocated weights to all 4 possible scenarios in confusion matrix and processed our 100 dollars through all the different models for different sets of thresholds. we have presented our findings and different set of confusion matrix in the appendix section.


#It turns out all of our models irrespective of the threshold are giving better profit than the risk free rate of 2% per annum.

lcdf %>% group_by(grade) %>% tally()
lcdf %>% group_by(grade) %>% summarise(mean(loan_amnt))
lcdf %>% group_by(loan_status, grade) %>% tally()
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"),
avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt))
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate),
stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet), stdRet=sd(annRet),
minRet=min(annRet), maxRet=max(annRet))
lcdf %>% select(loan_status, loan_amnt, total_pymnt, int_rate, actualTerm, actualReturn ) %>% view()
#Summaries
lcdf %>% group_by(loan_status) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet),
avgActualRet=mean(actualReturn), avgActualTerm=mean(actualTerm), minActualRet=min(actualReturn), maxActualRet=max(actualReturn))
#)Loans – performance by grade ?
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans,
avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100,
avgActualTerm=mean(actualTerm), minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)
lcdf %>% group_by(grade, loan_status) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans,
avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn),
avgActualTerm=mean(actualTerm), minActualRet=min(actualReturn), maxActualRet=max(actualReturn))
#Cost based performance – what cost/profit values to use?
lcdf %>% group_by(loan_status) %>% summarise(avgInt=mean(int_rate),avgActInt = mean(actualReturn*100))
#final table for the purpose of analysis
lcdf %>% group_by(grade,loan_status) %>% summarise(count=n(),avgInt=mean(int_rate),avgActInt = mean(actualReturn*100),avgActualTerm=mean(actualTerm),avgRet=mean(annRet))
lcdf %>% group_by(grade) %>% summarise(count=n(),avgInt=mean(int_rate),avgActInt = mean(actualReturn*100),avgActualTerm=mean(actualTerm),avgRet=mean(annRet),default_rate=sum(loan_status=="Charged Off")/n()*100, ThreeYearRet=(mean(annRet)*3+(3-mean(actualTerm))*2))
```

```{r}
#Ranger Evaluation
prPerfRF <- data.frame(scoreTst_FP)
prRetPerfRF <- cbind(prPerfRF, status=lcdfTst$loan_status, grade=lcdfTst$grade, actRet=lcdfTst$actualReturn, actTerm = lcdfTst$actualTerm)
prRetPerfRF <- prRetPerfRF %>% mutate(decile = ntile(-scoreTst_FP, 10))
prRetPerfRF %>% group_by(decile) %>% summarise(count=n(), numDefaults=sum(status=="Charged Off"), avgActRet=mean(actRet),
minRet=min(actRet), maxRet=max(actRet), avgTer=mean(actTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"),
totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
prRetPerfRF %>% group_by(decile) %>% summarise(count=n(), numDefaults=sum(status=="Charged Off"),goodloan=n()-sum(status=="Charged Off"), avgActRet=mean(actRet), riskfreerate=0.02, 
avgTer=mean(actTerm),
NetMoneyLCon100USD=  mean(actRet)* mean(actTerm)*100 + (3-mean(actTerm))*0.02*100,
NetMoneyCDon100USD=  0.02*3*100)
```


```{r}
#Use test dataset on all
#Profit Evaluation based on rpDT
rpTHRESH=0.3
predTrnProb=predict(rpDT2, lcdfTrn, type='prob')
predTstProb=predict(rpDT2, lcdfTst, type='prob')
# Confusion table
predTrnRP = ifelse(predTrnProb[, 'Charged Off'] >= rpTHRESH, 'Charged Off', 'Fully Paid')
table( pred = predTrnRP, true=lcdfTrn$loan_status)
predTstRP = ifelse(predTstProb[, 'Charged Off'] >= rpTHRESH, 'Charged Off', 'Fully Paid')
table( pred = predTstRP, true=lcdfTst$loan_status)
#Profit Evaluation based on ranger
rgTHRESH=0.3
predTrnProbRG=predict(rgModelProb, lcdfTrn)
predTstProbRG=predict(rgModelProb, lcdfTst)
# Confusion table
predTrnRG = ifelse(predTrnProbRG$predictions[, 'Charged Off'] >= rgTHRESH, 'Charged Off', 'Fully Paid')
table( pred = predTrnRG, true=lcdfTrn$loan_status)
lcdf %>% group_by(loan_status) %>% summarise(intRate = mean(int_rate), actTerm = mean(actualTerm), actRet = mean(actualReturn))
predTstRG = ifelse(predTstProbRG$predictions[, 'Charged Off'] >= rgTHRESH, 'Charged Off', 'Fully Paid')
table( pred = predTstRG, true=lcdfTst$loan_status)
lcdf %>% group_by(loan_status) %>% summarise(intRate = mean(int_rate), actTerm = mean(actualTerm), actRet = mean(actualReturn))
PROFITVAL <- 100*(0.0803*2.1+0.02*0.9)  #profit (on $100) from accurately identifying Fully_paid loans: 16.7827
COSTVAL <- 100*-0.117*3 # loss (on $100) from incorrectly predicting a Charged_Off loan as Full_paid: -35.1
prPerfRF <- cbind(prPerfRF, status=lcdfTst$loan_status)
prPerfRF <- prPerfRF[order(-scoreTst_FP) ,] #sort in desc order of prob(fully_paid)
#prPerfRF <- prPerfRF[ ,order(scoreTst_FP)] #sort in desc order of prob(fully_paid)
#typeof(prPerfRF)
#dim(prPerfRF)
#prPerfRF[1,]
#row_number(prPerfRF)
prPerfRF$profit <- ifelse(prPerfRF$status == 'Fully Paid', PROFITVAL, COSTVAL)
prPerfRF$cumProfit <- cumsum(prPerfRF$profit)
max(prPerfRF$cumProfit)
prPerfRF$cumProfit[which.max(prPerfRF$cumProfit)]
plot(prPerfRF$cumProfit)
scoreTst_FP_Limit1=prPerfRF$scoreTst_FP[prPerfRF$cumProfit==max(prPerfRF$cumProfit)]
scoreTst_FP_Limit1
prPerfRF$cumilaive_count <-seq.int(nrow(prPerfRF))
prPerfRF$AvgCumProfit=prPerfRF$cumProfit/prPerfRF$cumilaive_count
max(prPerfRF$AvgCumProfit)
scoreTst_FP_Limit2=prPerfRF$scoreTst_FP[prPerfRF$AvgCumProfit==max(prPerfRF$AvgCumProfit)]
scoreTst_FP_Limit2
plot(prPerfRF$AvgCumProfit)
prPerfRF$cumilaive_count_reverse <- nrow(prPerfRF)- seq.int(nrow(prPerfRF))
prPerfRF
sum(prPerfRF$profit)
prPerfRF$cumprofit_reverse= sum(prPerfRF$profit)-prPerfRF$cumProfit
prPerfRF$Avgcumprofit_reverse= prPerfRF$cumprofit_reverse/prPerfRF$cumilaive_count_reverse
scoreTst_FP_Limit3<-prPerfRF$scoreTst_FP[prPerfRF$Avgcumprofit_reverse<6]
length(scoreTst_FP_Limit3)
scoreTst_FP_Limit3[1]
plot(prPerfRF$Avgcumprofit_reverse)
  
```

```{r}
library(xgboost)
library(caret)
#Needs all data to be numeric -- so we convert categorical (i.e. factor) variables - # use the dummyVars function in the 'caret' package to convert factor variables to dummy-variables
dumVar<-dummyVars(~.,data=lcdf %>% select(-loan_status))
dxlcdf<- predict(dumVar,lcdf)
# for loan_status, check levels and convert to dummy vars and keep the class label of interest
levels(lcdf$loan_status)
dylcdf <- class2ind(lcdf$loan_status, drop2nd = FALSE)
# and then decide which one to keep
colcdf <- dylcdf [ , 1]# or,fplcdf <- dycldf [ , 2]  
#Training, test subsets
dxlcdfTrn <- dxlcdf[trnIndex,]
colcdfTrn <- colcdf[trnIndex]
dxlcdfTst <- dxlcdf[-trnIndex,]
colcdfTst <- colcdf[-trnIndex]
dxTrn <- xgb.DMatrix(subset(dxlcdfTrn, select=-c(annRet, actualTerm, actualReturn, total_pymnt)), label=colcdfTrn)
dxTst <- xgb.DMatrix( subset( dxlcdfTst,select=-c(annRet, actualTerm, actualReturn, total_pymnt)), label=colcdfTst)
xgbWatchlist <- list(train = dxTrn, eval = dxTst)
#we can watch the progress of learning thru performance on these datasets
#list of parameters for the xgboost model development functions
xgbMyParam <- list (
max_depth = 4, eta = 0.01,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")
#can specify which evaluation metrics we want to watch
xgb_lsM1 <- xgb.train( xgbMyParam, dxTrn, nrounds = 10, early_stopping_rounds = 10,
xgbWatchlist) #Stop if performance does not improve after 10 rounds
xgb_lsM1$best_iteration
xpredTrg<-predict(xgb_lsM1, dxTrn)
head(xpredTrg)
#confusion matrix
table(pred=as.numeric(xpredTrg>0.5), act=colcdfTrn)
#ROC, AUC performance
xpredTst<-predict(xgb_lsM1, dxTst)
pred_xgb_lsM1=prediction(xpredTst, lcdfTst$loan_status,label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_xgb_lsM1=performance(pred_xgb_lsM1, "tpr", "fpr")
plot(aucPerf_xgb_lsM1)
abline(a=0, b= 1)
#use cross-validation on training dataset to determine best model
xgbParam <- list (
max_depth = 4, eta = 0.01,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")
xgb_lscv <- xgb.cv( xgbParam, dxTrn, nrounds = 10, nfold=10, early_stopping_rounds = 10 )
#best iteration
xgb_lscv$best_iteration
# or for the best iteration based on performance measure (among those specified in xgbParam)
best_cvIter <- which.max(xgb_lscv$evaluation_log$test_auc_mean)
#best model
xgb_lsbest <- xgb.train(xgbParam, dxTrn, nrounds = xgb_lscv$best_iteration)
#variable importance
#xgb.importance(model = xgb_lsbest) %>% view()
xgb_lscv$evaluation_log
xpredBestTrg<-predict(xgb_lsbest, dxTrn)
head(xpredBestTrg)
#confusion matrix
xpredBestTrn<-predict(xgb_lsbest, dxTrn)
head(xpredBestTrn)
table(pred=as.numeric(xpredBestTrn>0.8), act=colcdfTrn)
xpredBestTst<-predict(xgb_lsbest, dxTst)
head(xpredBestTrn)
table(pred=as.numeric(xpredBestTrn>0.8), act=colcdfTrn)
#confusion matrix
table(pred=as.numeric(xpredBestTst>0.8), act=colcdfTst)
xpredBestTst<-predict(xgb_lsbest, dxTst)
#ROC, AUC performance
#On Train Data
pred_xgb_lsbest_trn=prediction(xpredBestTrn, lcdfTrn$loan_status,label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_xgb_lsbest_trn=performance(pred_xgb_lsbest_trn, "tpr", "fpr")
plot(aucPerf_xgb_lsbest_trn)
abline(a=0, b= 1)
xg_roc_Trn <- roc(lcdfTrn$loan_status, xpredBestTrn)
#On Test Data
pred_xgb_lsbest=prediction(xpredBestTst, lcdfTst$loan_status,label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_xgb_lsM1=performance(pred_xgb_lsM1, "tpr", "fpr")
plot(aucPerf_xgb_lsM1)
abline(a=0, b= 1)
xg_roc_Tst <- roc(lcdfTst$loan_status, xpredBestTst)
#Which hyper-parameters work best – experiment with a grid of parameter values
#xgbParamGrid <- expand.grid(
#max_depth = c(2, 5),
#eta = c(0.001, 0.01, 0.1) )
#xgbParam <- list (
#booster = "gbtree",
#objective = " binary:logistic",
#eta=0.01, #learning rate
#max_depth=5,
#min_child_weight=1,
#colsample_bytree=0.6
#)
#for(i in 1:nrow(xgbParamGrid)) {
#xgb_tune<- xgb.train(data=dxTrn,xgbParam,
#nrounds=1000, early_stopping_rounds = 10, xgbWatchlist,
#eta=xgbParamGrid$eta[i], max_depth=xgbParamGrid$max_depth[i] )
#xgbParamGrid$bestTree[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$iter
#xgbParamGrid$bestPerf[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$eval_auc
#}
```


```{r}
plot(rpDT2_roc_Trn,col="darkred", main = "ROC on Train Data")
plot(c5_roc_Trn,col="darkgreen",add=TRUE)
plot(rg_roc_Trn,col="orange",add=TRUE)
#plot(xg_roc_Trn,col="blue",add=TRUE)
legend(0.2,0.7, c('rpart','C5.0','ranger','xgboost'),lty=c(1,1), lwd=c(2,2),col=c('darkred','darkgreen','orange','blue'))
plot(rpDT2_roc_Tst,col="darkred", main = "ROC on Test Data")
plot(c5_roc_Tst,col="darkgreen",add=TRUE)
plot(rg_roc_Trn,col="orange",add=TRUE)
#plot(xg_roc_Tst,col="blue",add=TRUE)
legend(0.2,0.7, c('rpart','C5.0','ranger','xgboost'),lty=c(1,1), lwd=c(2,2),col=c('darkred','darkgreen','orange','blue'))
```

#8
```{r}
library(glmnet)
library(tidyverse)
library(lubridate)

#Decile table with glmnet for Actual Return

xD<- lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)
glmRet_cv<- cv.glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian")
plot(glmRet_cv)

#On Train Data
predRet_Trn_glm <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= predict(glmRet_cv, data.matrix(lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)),s="lambda.min" ))
predRet_Trn_glm <- predRet_Trn_glm %>% mutate(tile=ntile(-predRet, 10))
predRet_Trn_glm %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

#on Test Data
predRet_Tst_glm <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= predict(glmRet_cv, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)),
s="lambda.min" ))

predRet_Tst_glm <- predRet_Tst_glm %>% mutate(tile=ntile(-predRet, 10))

predRet_Tst_glm %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


# {r Ranger to Predict Actual Return}
library(ranger)


rfModel_Ret <- ranger(actualReturn ~., data=subset(lcdfTrn, select=-c(loan_status, annRet, actualTerm, total_pymnt)), importance = "permutation", num.trees =200)
rfPredRet_trn<- predict(rfModel_Ret, lcdfTrn)
sqrt(mean( (rfPredRet_trn$predictions - lcdfTrn$actualReturn)^2))
#sqrt(mean( ( (predict(rfModel_Ret, lcdfTst))$predictions - lcdfTst$actualReturn)^2))
plot ( (predict(rfModel_Ret, lcdfTrn))$predictions, lcdfTrn$actualReturn, main = "RF Actual Return Model on Training Data")
plot ( (predict(rfModel_Ret, lcdfTst))$predictions, lcdfTst$actualReturn, main = "RF Actual Return Model on Test Data")


#Performance by deciles on Trn
predRet_Trn_rf <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTrn))$predictions)

predRet_Trn_rf <- predRet_Trn_rf %>% mutate(tile=ntile(-predRet, 10))

predRet_Trn_rf %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"
), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

#Performance by deciles on Tst
predRet_Tst_rf <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTst))$predictions)

predRet_Tst_rf <- predRet_Tst_rf %>% mutate(tile=ntile(-predRet, 10))

predRet_Tst_rf %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"
), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


# {r XGB to predict actualReturn}
library(xgboost)
set.seed(12)

xDTrn_Ret <-lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -total_pymnt)
xDTst_Ret <-lcdfTst %>% select(-loan_status, -actualTerm, -annRet, -total_pymnt)


x = grep("actualReturn", colnames(xDTrn_Ret))

train_x = data.matrix(xDTrn_Ret[, -x])
train_y = data.matrix(xDTrn_Ret[,x])

test_x = data.matrix(xDTst_Ret[, -x])
test_y = data.matrix(xDTst_Ret[, x])

test_500_x = test_x[1:500,]
test_500_y = test_y[1:500,]

xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
xgb_500_test = xgb.DMatrix(data = test_500_x, label = test_500_y)

xgbParam_1 <- list (max.depth = 8, eval_metric="error", eta = 0.1)

#best model
xgb_lsbest_ret <- xgb.train(xgbParam_1, xgb_train, nrounds = 1000)


print(xgb_lsbest_ret)

pred_y = predict(xgb_lsbest_ret, xgb_test)

mse = mean((test_y - pred_y)^2)
mae = caret::MAE(test_y, pred_y)
rmse = caret::RMSE(test_y, pred_y)

cat("MSE: ", mse, "MAE: ", mae, " RMSE: ", rmse)

x = 1:length(test_y)
plot(x, test_y, col = "red", type = "l", main = "Prediction on All Test Data Points")
lines(x, pred_y, col = "blue", type = "l")
legend(x = 1, y = 38,  legend = c("original test_y", "predicted test_y"), col = c("red", "blue"), box.lty = 1, cex = 0.8, lty = c(1, 1))

pred_500_y = predict(xgb_lsbest_ret, xgb_500_test)

x = 1:length(test_500_y)
plot(x, test_500_y, col = "red", type = "l", main = "Prediction on 500 Test Data Points")
lines(x, pred_500_y, col = "blue", type = "l")
legend(x = 1, y = 38,  legend = c("original test_500_y", "predicted test_500_y"), col = c("red", "blue"), box.lty = 1, cex = 0.8, lty = c(1, 1))
plot ( (predict(xgb_lsbest_ret, train_x)), lcdfTrn$actualReturn, main = "XGB Actual Return Model on Training Data")
plot ( (predict(xgb_lsbest_ret, test_x)), lcdfTst$actualReturn, main = "XGB Actual Return Model on Test Data")

#Performance by deciles on Trn
predRet_Trn_xgb <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(xgb_lsbest_ret, train_x)))

predRet_Trn_xgb <- predRet_Trn_xgb %>% mutate(tile=ntile(-predRet, 10))

predRet_Trn_xgb %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"
), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

#Performance by deciles on Tst
predRet_Tst_xgb <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(xgb_lsbest_ret, test_x)))

predRet_Tst_xgb <- predRet_Tst_xgb %>% mutate(tile=ntile(-predRet, 10))

predRet_Tst_xgb %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"
), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```


#9
```{r}
# {r Ranger RF model for Loan Status}
rgModel1 <- ranger(loan_status ~., data=subset(bs_lcdfTrn, select=-c(annRet, actualTerm, actualReturn, total_pymnt)), num.trees =200, importance='permutation', mtry = 7, max.depth = 10, min.node.size = 30, sample.fraction = 0.5, replace=FALSE, respect.unordered.factors = "order" , verbose = TRUE , seed=0, probability = TRUE)



# {r XGB for Loan Status}

library(xgboost)
library(caret)

dumVar<-dummyVars(~.,data=lcdf %>% select(-loan_status))
dxlcdf<- predict(dumVar,lcdf)

# for loan_status, check levels and convert to dummy vars and keep the class label of interest
levels(lcdf$loan_status)
dylcdf <- class2ind(lcdf$loan_status, drop2nd = FALSE)
# and then decide which one to keep
colcdf <- dylcdf [ , 1]# or,fplcdf <- dycldf [ , 2]  

#Training, test subsets
dxlcdfTrn <- dxlcdf[trnIndex,]
colcdfTrn <- colcdf[trnIndex]
dxlcdfTst <- dxlcdf[-trnIndex,]
colcdfTst <- colcdf[-trnIndex]
dxTrn <- xgb.DMatrix(subset(dxlcdfTrn, select=-c(annRet, actualTerm, actualReturn, total_pymnt)), label=colcdfTrn)
dxTst <- xgb.DMatrix( subset( dxlcdfTst,select=-c(annRet, actualTerm, actualReturn, total_pymnt)), label=colcdfTst)


#use cross-validation on training dataset to determine best model
xgbParam <- list (
max_depth = 4, eta = 0.01,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")
xgb_lscv <- xgb.cv( xgbParam, dxTrn, nrounds = 10, nfold=10, early_stopping_rounds = 10 )
#best iteration
xgb_lscv$best_iteration
# or for the best iteration based on performance measure (among those specified in xgbParam)
best_cvIter <- which.max(xgb_lscv$evaluation_log$test_auc_mean)

#best model
xgb_lsbest <- xgb.train(xgbParam, dxTrn, nrounds = xgb_lscv$best_iteration)



## Combining predictions on ranger RF models

# {r Combining ranger models}

#Loan Status Model RF

rpredTst<-predict(rgModel1, lcdfTst)
scoreTst_FP <- rpredTst$predictions[,"Fully Paid"]

prPerfRF <- data.frame(scoreTst_FP)
prRetPerfRF <- cbind(prPerfRF, status=lcdfTst$loan_status, grade=lcdfTst$grade, actRet=lcdfTst$actualReturn, actTerm = lcdfTst$actualTerm)
prRetPerfRF <- prRetPerfRF %>% mutate(decile = ntile(-scoreTst_FP, 10))
prRetPerfRF %>% group_by(decile) %>% summarise(count=n(), numDefaults=sum(status=="Charged Off"), avgActRet=mean(actRet),
minRet=min(actRet), maxRet=max(actRet), avgTer=mean(actTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"),
totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


# Actual Return Model RF
predrfRet <- predict(rfModel_Ret, lcdfTst)
predrfRet_Tst <- lcdfTst %>% select(grade, loan_status, actualTerm, actualReturn, int_rate) %>%
mutate( predrfRet=predrfRet$predictions)
predrfRet_Tst <- predrfRet_Tst %>% mutate(tile=ntile(-predrfRet, 10))
predrfRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgPredRet=mean(predrfRet),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


#Combine both models using RF

d=1
pRetSc <- predrfRet_Tst %>% mutate(poScore=scoreTst_FP) #score scoreTst_rf_ls is from predicting loan_status. predrfRet_Tst is predicting actual return
pRet_d <- pRetSc %>% filter(tile<=d)
pRet_d<- pRet_d %>% mutate(tile2=ntile(-poScore, 20))
pRet_d %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predrfRet),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


## Combining predictions on XGB Models

# {r Combining XGB Models}

#Predicting loan status using XGB

xpredTst<-predict(xgb_lsbest, dxTst)

scoreTst_xgb_ls <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=xpredTst)

scoreTst_xgb_ls <- scoreTst_xgb_ls %>% mutate(tile=ntile(-score, 10))

scoreTst_xgb_ls %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

#Predicting Actual Return using XGB

xpredTst_ret<-predict(xgb_lsbest_ret, xgb_test)
predXgbRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
mutate( predXgbRet=xpredTst_ret)
predXgbRet_Tst <- predXgbRet_Tst %>% mutate(tile=ntile(-predXgbRet, 10))
predXgbRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgPredRet=mean(predXgbRet),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

#Combining both models


d=1
pRetSc_xgb <- predXgbRet_Tst %>% mutate(poScore=scoreTst_xgb_ls$score)
#score scoreTst_xgb_ls is from predicting loan_status. predXgbRet_Tst is predicting actual return

pRet_d_xgb <- pRetSc_xgb %>% filter(tile<=d)
pRet_d_xgb <- pRet_d_xgb %>% mutate(tile2=ntile(-poScore, 20))
pRet_d_xgb %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(xpredTst_ret),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


## Combining predictions on GLM Models

# {r Combining glm models}

# Loan Status Decile with glm
xDTst<-lcdfTst %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)

glmPredls_Tst=predict(glmlsw_cv,data.matrix(xDTst), s="lambda.min", type="response" )

preds_glm_Tst <- prediction(glmPredls_Tst, lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))

scoreTst_glm_ls <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=glmPredls_Tst)

scoreTst_glm_ls <- scoreTst_glm_ls %>% mutate(tile=ntile(-score, 10))

scoreTst_glm_ls %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(score), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


# Actual Return Decile with glm
glmPred_Tst_ret <- predict(glmRet_cv, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)),s="lambda.min")
predRet_Tst_glm <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= glmPred_Tst_ret)

predRet_Tst_glm <- predRet_Tst_glm %>% mutate(tile=ntile(-predRet, 10))

predRet_Tst_glm %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


d=1
pRetSc_glm <- predRet_Tst_glm %>% mutate(poScore=scoreTst_glm_ls$score) #score scoreTst_glm_ls is from predicting loan_status. predRet_Tst_glm is predicting actual return

pRet_d_glm <- pRetSc_glm %>% filter(tile<=d)
pRet_d_glm <- pRet_d_glm %>% mutate(tile2=ntile(-poScore, 20))
pRet_d_glm %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(glmPred_Tst_ret),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

#10

```{r}
# {r Modelling from lower loan grades with Ranger}


lg_lcdfTst<-lcdfTst %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
lg_lcdfTrn<-lcdfTrn %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')

rf_M1_lg <- ranger(loan_status ~., data=subset(lg_lcdfTrn, select=-c(annRet, actualTerm, actualReturn)), num.trees =200,
probability=TRUE, importance='permutation')
lg_scoreTstRF <- lg_lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
mutate(score=(predict(rf_M1_lg,lg_lcdfTst))$predictions[,"Fully Paid"])

lg_scoreTstRF <- lg_scoreTstRF %>% mutate(tile=ntile(-score, 10))

lg_scoreTstRF %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


# {r Modelling from lower loan grades with glm}

xDTrn_lg<-lg_lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)
yTrn_lg<-factor(if_else(lg_lcdfTrn$loan_status=="Fully Paid", '1', '0') )
wts_lg <- if_else(yTrn_lg == 0, 1-sum(yTrn_lg == 0)/length(yTrn_lg), 1-sum(yTrn_lg == 1)/length(yTrn_lg))

glmlsw_cv_lg<- cv.glmnet(data.matrix(xDTrn_lg), yTrn_lg, family= "binomial", weights = wts_lg, alpha = 1)

xDTst_lg<-lg_lcdfTst %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)

glmPredls_Tst_lg=predict(glmlsw_cv_lg,data.matrix(xDTst_lg), s="lambda.min", type="response" )

preds_glm_Tst_lg <- prediction(glmPredls_Tst_lg, lg_lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))

scoreTst_glm_ls_lg <- lg_lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=glmPredls_Tst_lg)

scoreTst_glm_ls_lg <- scoreTst_glm_ls_lg %>% mutate(tile=ntile(-score, 10))

scoreTst_glm_ls_lg %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(score), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )



# {r Modelling from lower loan grades with xgboost}

lg_lcdf<-lcdf %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')

nr_lg=nrow(lg_lcdf)
trnIndex_lg = sample(1:nr_lg, size = round(0.7*nr_lg), replace=FALSE)
lcdfTrn_lg=lg_lcdf[trnIndex_lg,]
lcdfTst_lg = lg_lcdf[-trnIndex_lg,]

dumVar_lg<-dummyVars(~.,data=lg_lcdf %>% select(-loan_status))
dxlcdf_lg<- predict(dumVar_lg,lg_lcdf)

# for loan_status, check levels and convert to dummy vars and keep the class label of interest
levels(lg_lcdf$loan_status)
dylcdf_lg <- class2ind(lg_lcdf$loan_status, drop2nd = FALSE)
# and then decide which one to keep
colcdf_lg <- dylcdf_lg [ , 1]# or,fplcdf <- dycldf [ , 2]  


#Training, test subsets
dxlcdfTrn_lg <- dxlcdf_lg[trnIndex_lg,]
colcdfTrn_lg <- colcdf_lg[trnIndex_lg]
dxlcdfTst_lg <- dxlcdf_lg[-trnIndex_lg,]
colcdfTst_lg <- colcdf_lg[-trnIndex_lg]
dxTrn_lg <- xgb.DMatrix(subset(dxlcdfTrn_lg, select=-c(annRet, actualTerm, actualReturn, total_pymnt)), label=colcdfTrn_lg)
dxTst_lg <- xgb.DMatrix( subset( dxlcdfTst_lg,select=-c(annRet, actualTerm, actualReturn, total_pymnt)), label=colcdfTst_lg)


#use cross-validation on training dataset to determine best model
xgbParam_lg <- list (
max_depth = 4, eta = 0.01,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")
xgb_lscv_lg <- xgb.cv( xgbParam_lg, dxTrn_lg, nrounds = 10, nfold=10, early_stopping_rounds = 10 )
#best iteration
xgb_lscv_lg$best_iteration
# or for the best iteration based on performance measure (among those specified in xgbParam)
best_cvIter_lg <- which.max(xgb_lscv_lg$evaluation_log$test_auc_mean)

#best model
xgb_lsbest_lg <- xgb.train(xgbParam_lg, dxTrn_lg, nrounds = xgb_lscv_lg$best_iteration)

xpredTst_lg<-predict(xgb_lsbest_lg, dxTst_lg)

scoreTst_xgb_ls_lg <- lcdfTst_lg %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=xpredTst_lg)

scoreTst_xgb_ls_lg <- scoreTst_xgb_ls_lg %>% mutate(tile=ntile(-score, 10))

scoreTst_xgb_ls_lg %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```








